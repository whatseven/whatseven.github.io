[{"title":"Coherent Occlusion Culling(CHC) 算法的原理与实现","date":"2018-03-22T13:04:06.000Z","path":"2018/03/22/Coherent-Occlusion-Culling-CHC-算法的原理与实现/","text":"CHC算法是Jiˇrí Bittner在2004年提出的一种遮挡剔除的算法，其中主要运用到了渲染的（Temporal coherence）时间相干性以及（Spatial coherence）空间相干性，同时运用BVH（Bounding Volume Hirachical）管理场景并且通过基于硬件的遮挡查询对遮挡物进行剔除，提高渲染速度。 算法背景Hardware Occlusion CullingCHC算法主要建立在基于硬件的遮挡查询（Hardware Occlusion Culling）的基础上。Hardware Occlusion Culling基于一个十分简单的思想，在判断物体是否被遮挡时，将物体的深度值传递给GPU，GPU将自己现存的最低的深度值与物体的深度值进行对比，并返回查询结果（可见像素点个数）。 优点 API简单易用，不需要额外管理信息，能迅速集成进现有系统 基于GPU进行判断，效率高，充分挖掘GPU性能 存在问题 基于GPU的判断效率高，但涉及数据传输，在大规模场景下会造成CPU一直等待GPU查询结果返回造成GPU性能饥饿的情况 虽然基于GPU判断效率高，不过在复杂场景下仍有大量渲染目标需要被测试，仍有提升空间 Coherent Occlusion Culling（CHC）目标 减少进行遮挡查询的次数 避免CPU出现瓶颈而GPU饥饿的情况 算法核心 利用BVH（Bounding Volume Hirachical）管理场景，并利用Spatial Coherence（空间相关性）减少每一帧需要进行遮挡查询的次数。 重用上一帧的查询结果，利用Time Coherence（时间相关性）进一步减少查询次数 维护一个查询队列，延迟进行查询的时间，并利用渲染部分场景的时间来填充CPU等待GPU查询结果返回的时间，减少GPU的饥饿。 算法介绍Spatial Coherence在实际的渲染过程中，一个渲染场景通常会有大量物体，如果将他们都渲染出来会对GPU造成极大的性能负担，所以需要对看不见的物体从渲染队列中剔除。例如View Frustum Culling算法：只渲染在视角范围内的物体。而对于一个复杂场景来说，经过View Frustum裁剪过后的物体对于渲染管线仍有很大压力。 而对于CHC算法的基础Hardware Occlusion Culling算法来说，对每一个物体都进行一次查询仍然是难以负担的任务。为了减少进行查询的次数，CHC算法的作者采用了一种层次化管理场景(BVH)的方法。将场景中的物体基于空间信息利用树状结构进行管理，相邻的物体存在于叶节点中。 Bounding Volume Hirachical (图片来源Wikipedia) 如图所示，场景中一共有6个物体，而树状结构一共有4个内部节点，每个物体都被它的父节点包围，每个内部节点也被它的父节点包围。 算法流程如下：在渲染开始时会从根节点依次往下遍历，并利用Hardware Occlusion Culling的方法检测节点包围盒对于当前场景是否可见，如果可见则遍历子节点直至叶节点。如不可见则证明该包围盒下所有节点都不可见，则跳过该节点继续遍历。 CHC-1 如上图，从根节点A开始遍历，发现右下角部分可视，则遍历子节点B与C。对于B节点的可见性测试失败，则跳过B节点的所有子节点，开始遍历C节点，直至遍历到叶节点开始渲染。 从上面例子中可以见到，通过这样一个场景管理的方法能够很有效的减少对于物体级别的操作次数。 Tips 在实际的遮挡物检测中，必须注意到物体渲染先后次数的问题。Hardware Occlusion Culling是将待查询物体的深度与屏幕缓存中现有物体深度进行比较，考虑物体A被物体B挡在后面，完全不可见。但遍历树时首先遍历到物体A，这是物体B还没有被渲染，那么物体A的可见性测试将是True。所以使用BVH结合Occlusion Culling是必须考虑以从前往后的方式遍历树结构。 在《Phisical Based Rendering》P297页介绍了一种成本很低的从前往后遍历的方法。具体实现见下方 Time Coherence即使利用了BVH管理场景，场景中仍具有大量待查询的物体。CHC算法的作者继续采用了一种假设的方法去消除一部分查询。 CHC算法将树内部的节点分为Open Node与Terminal Node（下文以O与T表示）。O是指上一帧可见的非叶节点。除此之外都是T（也就是上一帧不可见的节点或者是所有叶节点）。实际代码中是这样判断的： 1234//Is visible in last frame?bool wasVisible = curNode-&gt;visible &amp;&amp; (curNode-&gt;lastVisited == frameID - 1);//Is leaf node?bool opened = wasVisible &amp;&amp; !curNode-&gt;isLeaf; 在渲染的第一帧初始化两类节点的值，从第二帧的遍历开始，如果遇到O，则假设它这一帧能够被看到，初始化查询加入查询队列，但不等待查询结果返回就直接发出渲染命令，同时将可见性设为false。同时在每一次遍历新节点是查看队列中的查询结果，如果未返回则继续遍历，如果返回则处理查询结果并设置相应的可见性。 如果遇到T，初始化查询，并且阻塞到查询结果返回。 CHC算法的秘诀： 遍历时跳过所有O的可见度测试并默认通过，同时将其可见属性设为false，根据它的子叶节点的可见度测试结果重置它的可见属性。这种方法的作用是显而易见的，它有效的减少了执行可见度测试的次数，而他带来的影响： 假设上一帧可见的物体这一帧也可见：对于物体（叶节点）来说，在初始化查询后不等待其可见还是不可见的结果就立即发出渲染命令。这个假设第一不会影响到场景的正确性，因为所有的物体都会执行深度测试再次被裁剪。第二，初始化查询时将可见性设为false，这样在处理查询结果时也根据查询结果对这个节点以及其父节点赋予O或是T的属性从而影响到下一帧，也就是他的误差率是±1帧。 让CPU执行树的遍历与GPU执行可见性测试交错执行，这样能够有效的消除CPU的性能瓶颈以及GPU的饥饿。 CHC算法的流程图： 1234567891011121314151617181920212223242526272829303132333435363738394041424344while(true)&#123; //PART 1:Query and process finished queries while (!queryQueue.empty()|| doneTravel == true) &#123; if (!queryQueue.empty()&amp;&amp; resultAvailable(queryQueue.front())) &#123; //Previous invisible is ready //······ &#125; else if (!queryQueueForNextFrame.empty()&amp;&amp; resultAvailable(queryQueueForNextFrame.front())) &#123; //previous visible is ready //······ &#125; if (queryQueue.empty() &amp;&amp; queryQueueForNextFrame.empty()) break; &#125; //PART 2:Check if the algorithm is done if (queryQueue.empty() &amp;&amp; queryQueueForNextFrame.empty() &amp;&amp; doneTravel) break; //PART 3:traversal curNode = &amp;root[curVisitOffset]; bool wasVisible = curNode-&gt;visible &amp;&amp; (curNode-&gt;lastVisited == frameID - 1); bool opened = wasVisible &amp;&amp; !curNode-&gt;isLeaf; curNode-&gt;visible = false; curNode-&gt;lastVisited = frameID; if (!opened) &#123; issueOcculusionQuery(curNode,true); wasVisible ? queryQueueForNextFrame.push(curNode) : queryQueue.push(curNode); &#125; if (wasVisible) traversalNode(curNode, curVisitOffset, toVisit); if (curNode-&gt;isLeaf) &#123; //Travel in front-to-back order if (!toVisit.empty()) &#123; curVisitOffset = toVisit.top(); toVisit.pop(); &#125; else &#123; doneTravel = true; curVisitOffset = 0; &#125; &#125;&#125; 如图 这样，1.减少可见性查询的次数；2.消除CPU的性能瓶颈以及GPU的饥饿；两个目的就达到了~ 算法实现（关于BVH算法，《Phisical Based Rendering》P255-P308页有详细介绍，我的代码也是基于它实现的，读者可以自行查找或下载我的源代码） （我是将CHC算法用于VR引擎，会有左右眼渲染两次，所以有些时候会进行两次可见性测试，读者实验时可以删去多余代码） 定义变量1234567891011121314151617//All of the objectsObjects = gIsLeft? leftBvhAccel-&gt;getOrderedMesh():rightBvhAccel-&gt;getOrderedMesh();//For occlusion query(Terminal Node)std::queue&lt;LinearBVHNode*&gt; queryQueue; //For occlusion query(Open Node)std::queue&lt;LinearBVHNode*&gt; queryQueueForNextFrame; //For travel in front-back orderint curVisitOffset = 0; std::stack&lt;int&gt; toVisit;//For travelLinearBVHNode* curNode;LinearBVHNode* root = gIsLeft ? leftBvhAccel-&gt;getLinearNodes() : rightBvhAccel-&gt;getLinearNodes();//Judge the travel is donebool doneTravel = false; 循环主体1234567891011121314while(true)&#123; //PART 1:Query and process finished queries while (!queryQueue.empty()|| doneTravel == true) &#123; //······ &#125; //PART 2:Check if the algorithm is done if (queryQueue.empty() &amp;&amp; queryQueueForNextFrame.empty() &amp;&amp; doneTravel) break; //PART 3:traversal //······&#125; PART 1:Query and process finished queries123456789101112while (!queryQueue.empty()|| doneTravel == true) &#123; if (!queryQueue.empty()&amp;&amp; resultAvailable(queryQueue.front())) &#123; //Previous invisible is ready //······ &#125; else if (!queryQueueForNextFrame.empty()&amp;&amp; resultAvailable(queryQueueForNextFrame.front())) &#123; //previous visible is ready //······ &#125; if (queryQueue.empty() &amp;&amp; queryQueueForNextFrame.empty()) break;&#125; Previous invisible is ready 1234567891011121314151617181920212223242526272829303132333435363738if (!queryQueue.empty()&amp;&amp; resultAvailable(queryQueue.front())) &#123; //Previous invisible is ready curNode = queryQueue.front(); queryQueue.pop(); //If it is visible if (getOcculusionResult(curNode) &gt; 1) &#123; traversalNode(curNode, curVisitOffset, toVisit); pullUpVisibility(root, curNode); glDeleteQueriesARB(1, &amp;curNode-&gt;queryID); &#125; else &#123; //If it is not visible,query for the other eyes //It is only for VR! issueOcculusionQuery(curNode, false); if (getOcculusionResult(curNode) &gt; 1) &#123; //If the target is visible traversalNode(curNode, curVisitOffset, toVisit); //Set it&apos;s visible property as same as it&apos;s parent pullUpVisibility(root, curNode); glDeleteQueriesARB(1, &amp;curNode-&gt;queryID); &#125; else &#123; //The target is not visible if (toVisit.empty() &amp;&amp; curVisitOffset == 0) &#123; doneTravel = true; break; &#125; else if (toVisit.empty() &amp;&amp; !curNode-&gt;isLeaf) &#123; //the last invisible node doneTravel = true; break; &#125; else if (!curNode-&gt;isLeaf) &#123; //invisible node curVisitOffset = toVisit.top(); toVisit.pop(); &#125; &#125; &#125;&#125; Previous visible is ready 12345678910111213141516else if (!queryQueueForNextFrame.empty()&amp;&amp; resultAvailable(queryQueueForNextFrame.front())) &#123; //previous visible is ready curNode = queryQueueForNextFrame.front(); queryQueueForNextFrame.pop(); if (getOcculusionResult(curNode) &gt; 1) &#123; pullUpVisibility(root, curNode); glDeleteQueriesARB(1, &amp;curNode-&gt;queryID); &#125; else &#123; issueOcculusionQuery(curNode, false); if (getOcculusionResult(curNode) &gt; 1) &#123; pullUpVisibility(root, curNode); glDeleteQueriesARB(1, &amp;curNode-&gt;queryID); &#125; &#125;&#125; PART 3:Traversal123456789101112131415161718192021curNode = &amp;root[curVisitOffset];bool wasVisible = curNode-&gt;visible &amp;&amp; (curNode-&gt;lastVisited == frameID - 1);bool opened = wasVisible &amp;&amp; !curNode-&gt;isLeaf;curNode-&gt;visible = false;curNode-&gt;lastVisited = frameID;if (!opened) &#123; issueOcculusionQuery(curNode,true); wasVisible ? queryQueueForNextFrame.push(curNode) : queryQueue.push(curNode);&#125;if (wasVisible) traversalNode(curNode, curVisitOffset, toVisit);if (curNode-&gt;isLeaf) &#123; if (!toVisit.empty()) &#123; curVisitOffset = toVisit.top(); toVisit.pop(); &#125; else &#123; doneTravel = true; curVisitOffset = 0; &#125;&#125; Function:issueOcculusionQuery12345678910111213void issueOcculusionQuery(LinearBVHNode* vCurNode, bool isLeft) &#123; glDepthMask(GL_FALSE); glColorMask(GL_FALSE, GL_FALSE, GL_FALSE, GL_FALSE); glGenQueriesARB(1, &amp;(vCurNode-&gt;queryID)); glBeginQueryARB(GL_SAMPLES_PASSED_ARB, vCurNode-&gt;queryID); drawBound(vCurNode, isLeft); glEndQueryARB(GL_SAMPLES_PASSED_ARB); glDepthMask(GL_TRUE); glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE);&#125; Function:drawBound123void drawBound(LinearBVHNode* vCurNode, bool isLeft)&#123; //Draw the Node&apos;s Bounding Box&#125; Function:traversalNode12345678910111213141516171819202122void traversalNode(LinearBVHNode* curNode, int&amp; curVisitOffset, stack&lt;int&gt;&amp; toVisit) &#123; if (curNode-&gt;isLeaf) &#123; drawNode(curNode,true); glBindFramebuffer(GL_FRAMEBUFFER, 0); glBindFramebuffer(GL_FRAMEBUFFER, drawingRightFbo); drawNode(curNode,false); glBindFramebuffer(GL_FRAMEBUFFER, drawingLeftFbo); &#125; else &#123; glm::vec3 EyeToCentroid = curNode-&gt;bounds.getCentroid() - camera.Position; int DirisNeg[3]&#123; EyeToCentroid.x &lt; 0, EyeToCentroid.y &lt; 0, EyeToCentroid.z &lt; 0 &#125;; if (DirisNeg[curNode-&gt;axis]) &#123; toVisit.push(curVisitOffset + 1); curVisitOffset = curNode-&gt;secondChildOffset; &#125; else &#123; toVisit.push(curNode-&gt;secondChildOffset); ++curVisitOffset; &#125; &#125;&#125; Function:pullUpVisibility123456void pullUpVisibility(LinearBVHNode* root, LinearBVHNode* curNode) &#123; while (!curNode-&gt;visible) &#123; curNode-&gt;visible = true; curNode = &amp;root[curNode-&gt;parentOffset]; &#125;&#125; Function:getOcculusionResult12345GLuint getOcculusionResult(LinearBVHNode* curNode) &#123; GLuint sampleCount; glGetQueryObjectuivARB(curNode-&gt;queryID, GL_QUERY_RESULT_ARB, &amp;sampleCount); return sampleCount;&#125; Function:resultAvailable123456bool resultAvailable(LinearBVHNode* node) &#123; GLint available; glGetQueryObjectivARB(node-&gt;queryID, GL_QUERY_RESULT_AVAILABLE_ARB, &amp;available); // glGetOcclusionQueryuivNV(node-&gt;queryID, GL_PIXEL_COUNT_AVAILABLE_NV,&amp;available); return available;&#125; 项目地址Github(喜欢就star一个哇~)","tags":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"blog.llsevenr.cn/tags/Computer-Graphics/"},{"name":"Occlusion Culling","slug":"Occlusion-Culling","permalink":"blog.llsevenr.cn/tags/Occlusion-Culling/"}]},{"title":"用OpenCV进行相机标定","date":"2017-09-01T10:50:13.000Z","path":"2017/09/01/用OpenCV进行相机标定/","text":"相机标定的原理成像模型相机在计算机视觉应用中起着重要作用，作为图像数据来源，影响着后续各个处理步骤。成像模型就是用数学公式刻画整个成像过程，即被拍摄物体空间点到照片成像点之间的几何变换关系。 总体上，相机成像可以分为四个步骤：刚体变换、透视投影、畸变校正和数字化图像。 相机成像模型 刚体变换刚体变换只改变物体的空间位置(平移)和朝向(旋转)，而不改变其形状，可用两个变量来描述：旋转矩阵R和平移向量t 刚体变换 齐次坐标下可写为： 刚体变换 旋转矩阵R是正交矩阵，可通过罗德里格斯（Rodrigues）变换转换为只有三个独立变量的旋转向量： Rodrigues 因此，刚体变换可用6个参数来描述，这6个参数就称为相机的外参(Extrinsic)，相机外参决定了空间点从世界坐标系转换到相机坐标系的变换，也可以说外参描述了相机在世界坐标系中的位置和朝向。 透视投影我们可以将透镜的成像简单地抽象成下图所示： 透视投影 设 f=OB 表示透镜的焦距，m=OC 为像距，n=AO 为物距，有： 焦距 一般地，由于物距远大于焦距，即 n&gt;&gt;f，所以 m≈f，此时可以用小孔模型代替透镜成像： 小孔成像 可得： 齐次坐标下有： 如果将成像平面移到相机光心与物体之间，则有中心透视模型： 小孔 可得： 齐次坐标下有： 总体上看，透视投影将相机坐标系中的点投影到理想图像坐标系，其变换过程只与相机焦距 f 有关。 畸变校正理想的针孔成像模型确定的坐标变换关系均为线性的，而实际上，现实中使用的相机由于镜头中镜片因为光线的通过产生的不规则的折射，镜头畸变（lens distortion）总是存在的，即根据理想针孔成像模型计算出来的像点坐标与实际坐标存在偏差。畸变的引入使得成像模型中的几何变换关系变为非线性，增加了模型的复杂度，但更接近真实情形。畸变导致的成像失真可分为径向失真和切向失真两类： 畸变类型很多，总体上可分为径向畸变和切向畸变两类，径向畸变的形成原因是镜头制造工艺不完美，使得镜头形状存在缺陷，包括枕形畸变和桶形畸变等，可以用如下表达式来描述： 切向畸变又分为薄透镜畸变和离心畸变等，薄透镜畸变则是因为透镜存在一定的细微倾斜造成的；离心畸变的形成原因是镜头是由多个透镜组合而成的，而各个透镜的光轴不在同一条中心线上。切向畸变可以用如下数学表达式来描述： 在引入镜头的畸变后，成像点从理想图像坐标系到真实图像坐标系的变换关系可以表示为： 实际计算过程中，如果考虑太多高阶的畸变参数，会导致标定求解的不稳定。 数字化图像光线通过相机镜头后最终成像在感光阵列(CCD或CMOS)上，然后感光阵列将光信号转化为电信号，最后形成完整的图像。我们用dx和dy分别表示感光阵列的每个点在x和y方向上物理尺寸，即一个像素是多少毫米，这两个值一般比较接近，但由于制造工艺的精度问题，会有一定误差，同样的，感光阵列的法向和相机光轴也不是完全重合，即可以看作成像平面与光轴不垂直。 我们用仿射变换来描述这个过程，如上图，O点是图像中心点，对应图像坐标(u0，v0)，Xd - Yd是真实图像坐标系，U-V是数字化图像坐标系，有： 齐次坐标下有： 上式中的变换矩阵即为相机的内参数矩阵 K，其描述了相机坐标系中点到二维图像上点的变换过程。 综上所述，在不考虑镜头畸变的情况下，相机的整个成像过程可表示为，其中R,T为旋转矩阵和平移矩阵，为相机的外参数： 若考虑畸变，则为 相机标定的步骤 准备标定图片 对每一张标定图片，提取角点信息 对每一张标定图片，进一步提取亚像素角点信息 相机标定 查看标定效果——利用标定结果对棋盘图进行矫正 基于OpenCV的相机标定实现定义全局变量首先定义全局变量12345678910111213141516171819202122#include &quot;opencv2/core/core.hpp&quot;#include &quot;opencv2/imgproc/imgproc.hpp&quot;#include &quot;opencv2/calib3d/calib3d.hpp&quot;#include &quot;opencv2/highgui/highgui.hpp&quot;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &quot;Calibration.h&quot;using namespace cv;using namespace std;int image_count = 0; // 图像数量Size board_size = Size(6, 4); // 标定板上每行、列的角点数Size image_size; // 图像的尺寸vector&lt;vector&lt;Point2f&gt;&gt; image_points_seq; // 保存检测到的所有角点Mat cameraMatrix = Mat(3, 3, CV_32FC1, Scalar::all(0)); // 摄像机内参数矩阵Mat distCoeffs = Mat(1, 5, CV_32FC1, Scalar::all(0)); // 摄像机的5个畸变系数：k1,k2,p1,p2,k3void findCheese(string filename);void myCalibration(string filename);void correctFile(); 读入图片并寻找角点然后读入储存图片路径的文本文件，读入图片并且寻找图片角点12345678910111213141516171819202122232425262728293031323334353637383940void findCheese(string filename) &#123; vector&lt;Point2f&gt; image_points_buf; // 缓存每幅图像上检测到的角点 cout &lt;&lt; &quot;开始提取角点&quot;; ifstream fin(filename); while (getline(fin, filename)) &#123; image_count++; cout &lt;&lt; &quot;Solve image = &quot; &lt;&lt; image_count &lt;&lt; endl; Mat imageInput = imread(filename); if (image_count == 1) //读入第一张图片时获取图像宽高信息,标定需要 &#123; image_size.width = imageInput.cols; image_size.height = imageInput.rows; cout &lt;&lt; &quot;image_size.width = &quot; &lt;&lt; image_size.width &lt;&lt; endl; cout &lt;&lt; &quot;image_size.height = &quot; &lt;&lt; image_size.height &lt;&lt; endl; &#125; /* 提取角点 */ if (0 == findChessboardCorners(imageInput, board_size, image_points_buf)) &#123; cout &lt;&lt; &quot;can not find chessboard corners!\\n&quot;; //找不到角点 exit(1); &#125; else &#123; Mat view_gray; cvtColor(imageInput, view_gray, CV_RGB2GRAY); /* 亚像素精确化 */ find4QuadCornerSubpix(view_gray, image_points_buf, Size(5, 5)); //对粗提取的角点进行精确化 //cornerSubPix(view_gray,image_points_buf,Size(5,5),Size(-1,-1),TermCriteria(CV_TERMCRIT_EPS+CV_TERMCRIT_ITER,30,0.1)); image_points_seq.push_back(image_points_buf); //保存亚像素角点 //drawChessboardCorners(view_gray, board_size, image_points_buf, false); //用于在图片中标记角点 //imshow(&quot;Camera Calibration&quot;, view_gray);//显示图片 //waitKey(500);//暂停0.5S &#125; &#125; cout &lt;&lt; &quot;角点提取完成！\\n&quot;;&#125; 进行标定，寻找内参数与畸变参数12345678910111213141516171819202122232425262728293031323334353637383940414243void myCalibration(string filename) &#123; cout &lt;&lt; &quot;开始标定………………&quot;; /*棋盘三维信息*/ Size square_size = Size(10, 10); /* 实际测量得到的标定板上每个棋盘格的大小 */ vector&lt;vector&lt;Point3f&gt;&gt; object_points; /* 保存标定板上角点的三维坐标 */ vector&lt;Mat&gt; tvecsMat; /* 每幅图像的旋转向量 */ vector&lt;Mat&gt; rvecsMat; /* 每幅图像的平移向量 */ /* 初始化标定板上角点的三维坐标 */ int i, j, t; for (t = 0; t&lt;image_count; t++) &#123; vector&lt;Point3f&gt; tempPointSet; for (i = 0; i&lt;board_size.height; i++) &#123; for (j = 0; j&lt;board_size.width; j++) &#123; Point3f realPoint; /* 假设标定板放在世界坐标系中z=0的平面上 */ realPoint.x = i*square_size.width; realPoint.y = j*square_size.height; realPoint.z = 0; tempPointSet.push_back(realPoint); &#125; &#125; object_points.push_back(tempPointSet); &#125; /* 开始标定 */ calibrateCamera(object_points, image_points_seq, image_size, cameraMatrix, distCoeffs, rvecsMat, tvecsMat, 0); cout &lt;&lt; &quot;标定完成！\\n&quot;; //保存标定结果 ofstream fout(filename); // 保存标定结果的文件 std::cout &lt;&lt; &quot;开始保存定标结果………………&quot; &lt;&lt; endl; fout &lt;&lt; &quot;相机内参数矩阵：&quot; &lt;&lt; endl; fout &lt;&lt; cameraMatrix &lt;&lt; endl &lt;&lt; endl; fout &lt;&lt; &quot;畸变系数：\\n&quot;; fout &lt;&lt; distCoeffs &lt;&lt; endl &lt;&lt; endl &lt;&lt; endl; std::cout &lt;&lt; &quot;完成保存&quot; &lt;&lt; endl; fout &lt;&lt; endl;&#125; 进行图像矫正1234567891011121314151617181920212223242526272829303132void correctFile() &#123; Mat mapx = Mat(image_size, CV_32FC1); Mat mapy = Mat(image_size, CV_32FC1); Mat R = Mat::eye(3, 3, CV_32F); std::cout &lt;&lt; &quot;保存矫正图像&quot; &lt;&lt; endl; string imageFileName; std::stringstream StrStm; for (int i = 0; i != image_count; i++) &#123; std::cout &lt;&lt; &quot;Save &quot; &lt;&lt; i + 1 &lt;&lt; &quot;...&quot; &lt;&lt; endl; initUndistortRectifyMap(cameraMatrix, distCoeffs, R, cameraMatrix, image_size, CV_32FC1, mapx, mapy); StrStm.clear(); imageFileName.clear(); string filePath = &quot;C:\\\\Users\\\\whatseven\\\\Desktop\\\\project\\\\C++\\\\Calibration\\\\Calibration\\\\image\\\\chess&quot;; StrStm &lt;&lt; i + 1; StrStm &gt;&gt; imageFileName; filePath += imageFileName; filePath += &quot;.bmp&quot;; Mat imageSource = imread(filePath); Mat newimage = imageSource.clone(); //另一种不需要转换矩阵的方式 //undistort(imageSource,newimage,cameraMatrix,distCoeffs); remap(imageSource, newimage, mapx, mapy, INTER_LINEAR); StrStm.clear(); filePath.clear(); StrStm &lt;&lt; i + 1; StrStm &gt;&gt; imageFileName; imageFileName += &quot;_d.jpg&quot;; imwrite(imageFileName, newimage); &#125; std::cout &lt;&lt; &quot;保存结束&quot; &lt;&lt; endl;&#125; 调用函数12345678910111213void main()&#123; string inputFile = &quot;calibdata.txt&quot;; string outputFile = &quot;caliberation_result.txt&quot;; findCheese(inputFile); //找到角点 myCalibration(outputFile); //标定，找到参数矩阵及畸变系数 correctFile(); //储存矫正后图片 return;&#125; 标定结果 Github项目地址 利用Matlab进行标定CameraCalibrator工具 在Matlab命令行里，输入cameraCalibrator打开标定程序 选择Add images将图片导入 单击Calibration即可开始标定，再点击Export Camera Parameters即可导出相机参数","tags":[{"name":"Computer Vision","slug":"Computer-Vision","permalink":"blog.llsevenr.cn/tags/Computer-Vision/"}]},{"title":"基于python实现朴素贝叶斯算法","date":"2017-08-30T01:35:25.000Z","path":"2017/08/30/基于python实现朴素贝叶斯算法/","text":"朴素贝叶斯算法总结(有关朴素贝叶斯算法的原理可可参考算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification)) 下面对朴素贝叶斯算法进行粗略的总结，并可以根据这个总结搭建朴素贝叶斯算法的框架 首先，将朴素贝叶斯算法分为数据预处理-&gt;训练-&gt;识别三个模块，以下是完成Titanic预测后对算法的总结，对应的算法实现部分都有相应的实例 //Tasking图 在数据预处理部分，我们对原始数据进行预处理，将数据转化为自己想要的格式，例如 对一些属性及结果进行划分 字符串-&gt;可操作格式(例如int) 抛弃不需要的属性值 填补空缺值在完成数据预处理后，预期得到 dataMatrix矩阵：存储模型所需要数据的值，横向为不同的属性，纵向为不同的记录。 cateVec向量：存储分类结果，与dataMatrix的记录一一对应，也就是说cateVec的长度与dataMatrix的记录数相等 在训练部分，我们将dataMatrix与cateVec输入，并计算每一个划分的先验概率P（ai=j|C=k）并进行分类 通过计算一个属性的一个划分在这个类别中出现的次数除以这个类别出现的总次数得到划分的先验概率，也就是P（ai=j|C=k） 计算类别的概率P（C=k）在第一点中，我们期望得到的应该是所有属性的所有划分的概率，例如我们两个属性一个有两个划分，一个有三个划分，那一共期望的输出应该是5个概率期望输出： 有多少个类别就输出多少个字典，其中字典的key是属性与值（也就是划分），值是相应的概率，例如survived[age=1]=2/5(age=1代表age处于第一个划分) cateRate：输出类别的概率向量（P（C=k）） 识别部分，我们通过贝叶斯公式用每一个类别在训练步骤得到的字典去计算他在那一个类别的概率，通过贝叶斯公式我们了解到，这个概率为//贝叶斯公式所以在识别部分，我们将待识别的记录构造成与dataMatrix的记录格式相同的记录并作为输入： 计算输入的记录在每一个类别的后验概率（tips：通过在对应属性的dict中找到ai=j这样的记录获取相应划分的概率） 取最大值期望输出： 根据最大值输出相应的类别 至此，识别完成 Todo：将不同划分的概率值通过以[ai=j]这样的key储存在字典里效率很低，希望以后寻找到更好的解决办法 算法实现下列算法只是粗糙的基于Python实现，使用Titanic.dat数据集，用前800条数据进行训练并用后82条数据测试，正确率为81%左右 预处理部分与前面的总结对应，首先进行数据的预处理，首先读入训练数据，定义需要输出的dataMatrix和cateVec向量12345def preProcess(): # 通过csv模块读入训练数据 reader=csv.reader(open(&quot;train.csv&quot;)) cateVec=[] dataMatrix=[] 循环train.csv的每一条数据，首先提取需要的属性并将没有值的数据设为默认值123456789for id,sur,pc,name,sex,age,sib,par,tic,fare,car,emb in reader: # 标题行跳过 if(id==&apos;PassengerId&apos;): continue # 提取需要数据 line = [pc, sex, age, sib, par] # 给空值填充值 for i in range(len(line)): if (len(line[i])==0): 将数据处理为需要的格式并处理划分12345678910111213141516171819202122232425262728293031323334#转化为需要的格式age=float(line[2])sib=int(line[3])par=int(line[4])sur=int(sur)# 划分数据ageTemp = &apos;0&apos;if 0 &lt; age and age &lt; 10: ageTemp = &apos;1&apos;elif 10 &lt;= age &lt; 20: ageTemp = &apos;2&apos;elif 20 &lt;= age &lt; 30: ageTemp = &apos;3&apos;elif 30 &lt;= age &lt; 40: ageTemp = &apos;4&apos;elif age &gt;= 40: ageTemp = &apos;5&apos;sibspTemp = &apos;0&apos;if sib == 1: sibspTemp = &apos;1&apos;elif sib == 2: sibspTemp = &apos;2&apos;elif sib &gt; 2: sibspTemp = &apos;3&apos;parchTemp = &apos;0&apos;if par == 1: parchTemp = &apos;1&apos;elif par == 2: parchTemp = &apos;2&apos;elif par &gt; 2: parchTemp = &apos;3&apos; 将类别加入类别集合，每一条处理完的数据加入数据矩阵,最后返回123 cateVec.append(sur) dataMatrix.append([pc, &apos;1&apos; if sex == &apos;male&apos; else &apos;0&apos;, ageTemp, sibspTemp, parchTemp])return dataMatrix,cateVec 训练部分下列是训练部分首先算出需要输出的类别概率P（C=0）123def train(data, cateVec): # 类别概率（P（C=0）） surRate=sum(cateVec)/len(cateVec) 然后循环计算需要输出的每个划分出现的次数12345678910111213141516# 不同类别下不同划分的次数surVec=&#123;&#125;unsurVec=&#123;&#125;# 循环dataMatrix里的每一个属性，根据不同的类别统计其对应的划分的次数for i in range(len(data)): for j in range(len(data[i])):# 循环一条记录的每一个属性，存入的字符串形如&quot;0=2&quot;，代表第一个属性在第二个划分区间里的次数 if(cateVec[i]==0): # 如果未幸存 if (str(j)+&apos;=&apos;+data[i][j]) in unsurVec: unsurVec[(str(j)+&apos;=&apos;+data[i][j])]+=1 else: unsurVec[(str(j)+&apos;=&apos; + data[i][j])] =1 else:# 如果幸存 if (str(j)+&apos;=&apos;+data[i][j]) in surVec: surVec[(str(j)+&apos;=&apos;+data[i][j])]+=1 else: surVec[(str(j)+&apos;=&apos; + data[i][j])] =1 将次数除以类别出现的次数即为相应的先验概率（P（ai=j|C=k））123456789# 对于储存的每一个值除以类别的概率即为P（ai=j|C=k） for key in unsurVec.keys(): targetStr = key[key.find(&apos;|&apos;) + 1:] unsurVec[key]/=(len(cateVec) * (1 - surRate)) for key in surVec.keys(): targetStr = key[key.find(&apos;|&apos;) + 1:] surVec[key]/=(len(cateVec) * surRate) return unsurVec,surVec,surRate 识别部分识别部分将输入的向量构造成形如字典存储的”0=2”的形式，代表第0个属性值为2（处于第二个划分），再到不同类别的概率字典中取出值乘以类别的概率，即（P（ai=j|C=k）*（P（C=k）））为贝叶斯公式的分子，因为分母相同，取分子最大的类别即为结果1234567891011121314def classify(feature,unsurVec,surVec,survivedRate): # 初始化结果概率 survivedPos=1 unsurvivedPos=1 # 对于每一个属性，计算P(ai=j|C=k)，并将结果乘入对应类别的结果概率 for i in range(len(feature)): tempStr=str(i)+&apos;=&apos;+feature[i] survivedPos*=surVec[tempStr] unsurvivedPos*=unsurVec[tempStr] # 计算P(ai=j|C=k)*P（C=k） survivedPos*=survivedRate unsurvivedPos*=(1-survivedRate) # 返回概率大的类别 return 1 if survivedPos&gt;unsurvivedPos else 0 主程序调用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455data,survived=preProcess()unsurVec,surVec,surRate=train(data,survived)k=0 # 准确的个数total=92 # 测试个数# 对输入数据预处理，得到与dataMatrix相同的数据格式reader=csv.reader(open(&quot;test.csv&quot;))for id, sur, pc, name, sex, age, sib, par, tic, fare, car, emb in reader: if (id == &apos;PassengerId&apos;): continue temp = [pc, sex, age, sib, par] for i in range(len(temp)): if (len(temp[i]) == 0): temp[i] = 1 age = float(temp[2]) sib = int(temp[3]) par = int(temp[4]) ageTemp = &apos;0&apos; if 0 &lt; age and age &lt; 10: ageTemp = &apos;1&apos; elif 10 &lt;= age &lt; 20: ageTemp = &apos;2&apos; elif 20 &lt;= age &lt; 30: ageTemp = &apos;3&apos; elif 30 &lt;= age &lt; 40: ageTemp = &apos;4&apos; elif age &gt;= 40: ageTemp = &apos;5&apos; sibspTemp = &apos;0&apos; if sib == 1: sibspTemp = &apos;1&apos; elif sib == 2: sibspTemp = &apos;2&apos; elif sib &gt; 2: sibspTemp = &apos;3&apos; parchTemp = &apos;0&apos; if par == 1: parchTemp = &apos;1&apos; elif par == 2: parchTemp = &apos;2&apos; elif par &gt; 2: parchTemp = &apos;3&apos; temp = [pc, &apos;1&apos; if sex == &apos;male&apos; else &apos;0&apos;, ageTemp, sibspTemp, parchTemp] # 判断识别结果 if(classify(temp,unsurVec,surVec,surRate)==int(sur)): k+=1# 输出识别率 print(k/total) Github项目地址 Todo对于先验概率的储存还是不太满意，应该会有更好的数据结构用来存储对于每一个类别，每一个属性的每一个划分的值 #参考资料： 算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification)","tags":[{"name":"Machine Lerning","slug":"Machine-Lerning","permalink":"blog.llsevenr.cn/tags/Machine-Lerning/"},{"name":"Python","slug":"Python","permalink":"blog.llsevenr.cn/tags/Python/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"blog.llsevenr.cn/tags/Computer-Vision/"}]},{"title":"搭建Git服务器及多人协作开发常见命令","date":"2017-08-10T10:35:59.000Z","path":"2017/08/10/搭建Git服务器及多人协作开发常见命令/","text":"搭建Git服务器Github的项目必须为开放的并且在中国的访问速度如无特殊配置通常访问很慢，于是便想在自己的服务器上搭建Git仓库，同时也具备多人协作开发的能力。 配置Git和用户首先安装Git sudo apt install git 配置单独用来访问仓库的git用户 12groupadd gitadduser git -g git 创建SSL证书登录在支持bash的命令行下，输入 ssh-keygen -C &#39;your@email.com&#39; -t rsa 为你生成rsa密钥，可以直接一路回车，执行默认操作，生成的密钥可以在这儿找到123C://users//&lt;电脑账户名&gt;//.ssh├── id_rsa└── id_rsa.pub #公钥 服务端需要里边内容验证连接着身份 将SSH添加到管理 ssh-add id_rsa 将公钥里面的内容完整输入至/home/git/.ssh/authorized_keys，一行一个密钥 Tips：多公钥管理在.ssh目录下配置config文件，再将SSH加入SSH管理，格式如下：12345Host github.com //连接域名 HostName github.com //域名名称 User whatseven //用户 IdentityFile C:\\Users\\whatseven\\.ssh\\id_rsa_github //对应私钥 PreferredAuthentications publickey Git多人协作开发常用命令完成上述步骤，就能够在自己的服务器上建立仓库并且作为远程分支与本地分支建立联系了，下面是在多人协作开发的一些常用的Git命令。 建立裸仓库在建好的服务器里新建文件夹，在文件夹下使用git init --bare新建裸仓库，只存放版本库信息。 开发人员A上用git clone 仓库地址 仓库在本机的命名克隆仓库，开始自己的本地开发。 Tips：为什么要建立裸仓库？在Git中，如果向普通代码仓库push的话，Git会将推送的内容与工作文件进行比较，它会认为工作文件发生改变，从而影响工作树，常见的是在想远程目标的当前分支push代码时，在远程终端必须使用git reset --hard。而裸代码仓库由于没有工作树，所以push所含的变化仅影响裸代码仓库的版本控制。 在裸仓库中，工作目录下除了版本库信息没有任何东西，会给大家造成一个误解以为裸仓库只记录版本，没有文件。其实在Git系统中，文件是通过不同的对象例如索引，树，块存与版本库里面的，所以裸仓库看似工作目录是空的，在克隆裸仓库是git会将对象从版本库取出并根据版本更改信息组织到正确的位置 在开发过程中，一般会将项目分为几个分支。 Git分支策略 Git分支策略 master分支应该保存重大的版本或节点，开发前应保持远程与本地同步 dev是日常开发分支，平时的开发应在dev上进行，开发前应保持远程与本地同步 剩下的是个人分支，个人的开发在个人分支上进行，在每天或者一个阶段的工作结束后每个人将自己的代码合并到dev分支上。个人分支不用同步至远程分支 开发实例下面通过两个开发人员实例演示多人开发： 开发人员A通过git clone git@111.111.111.111:/home/git/repo/test.git test.git将远程的版本库克隆至本机 如无dev分支，A通过git checkout -b dev从master分支创建dev分支 A再次通过git checkout -b A从dev分支上创建自己的开发分支 A在工作目录里新建内容为”A”的A.txt，再创建内容为”公共”的公共.txt A通过git add A.txt 公共.txt与git commit -m &quot;init A,公共&quot;提交更改 当A完成阶段性工作后，通过git checkout dev切换至开发分支，再通过git merge --no-ff A将A分支合并到dev分支,如有冲突则在文件中去删除多余部分 A剩下的工作是要将自己的工作推到大家代码的源头–位于远程的裸仓库中，在Git中，本机Git版本库与远程库的连接是基于分支的，例如本机的master与远程的master有一条链接，本机的dev也应该与远程dev有一个链接。 A通过在dev分支上git push -u origin dev将本机的dev分支的更新推送到远程dev分支上去，-u选项是指在未建立链接的情况下建立一条链接，以后推送更新就只用git push即可 此时，A的工作已经全部做完了，当B开始工作时，他必须获取远程库的最新情况以保证自己的工作是建立在最新的工作上的，它可以在建立了链接的情况下通过git pull将远程更新拉到本地，后续操作类似A。","tags":[{"name":"Git","slug":"Git","permalink":"blog.llsevenr.cn/tags/Git/"},{"name":"分支策略","slug":"分支策略","permalink":"blog.llsevenr.cn/tags/分支策略/"}]},{"title":"JavaScript常见集合操作","date":"2017-08-09T13:37:20.000Z","path":"2017/08/09/JavaScript常见集合操作/","text":"集合的遍历for循环(效率最高) 优点：JavaScript最普遍的for循环，执行效率最高 缺点：无法遍历对象 123for(let i=0;i&lt;array.length,i++)&#123; //operation&#125; for…in循环(效率较低) 优点：唯一一个能够获取对象的属性名的遍历方式 缺点：会将对象通过继承得到的属性一齐遍历，造成非预料的结果且效率较低 1234//会访问非继承的属性for(attr in object)&#123;//attr作为属性名 //object[attr]访问值&#125; 123456//避免访问继承的属性for(attr in object)&#123;//attr作为属性名 if(object.hasOwnProperty(attr))&#123; //object[attr]访问值 &#125;&#125; for…of循环(效率较高) 优点：能够快速访问非继承属性值 缺点：需要ES6支持 123for(item of object)&#123; //item访问值&#125; forEach方法(数组内置高阶方法，含义清晰) 优点：函数式编程，简洁，快速领会代码含义 缺点：无法对对象使用 12345array.forEach(function(item,index,array))&#123; //item为值 //index为索引 //array为被访问数组&#125;; Tips: 在对对象进行遍历时，如不需要访问属性名选择for...of循环，如需访问属性名选择for...in循环 在对数组进行访问时，使用forEach得到较好的可读性，传统的for循环能够带来很高的性能及拓展性 集合的操作在小波老师提倡的想机器一样思考中，编程问题的解决被分为了输入，处理和输出 像机器一样思考 引用自像机器一样思考（一）—— 宏观的基础 处理，是对输入数据的处理，就可以分为从输入的数据中提炼出一定的有价值的数据，并对他们做出一些操作，得到希望得到的有价值的东西，并将他输出 Map映射Map映射是将输入的数据中有价值的东西提取出来，转化为更有利于处理的格式123456let dataAfterProcess = array.map(function(item,index,array)&#123; //item为值 //index为索引 //array为被访问数组 return ;//返回dataAfterProcess中希望被添加的元素&#125;); Reduce计算Reduce计算以提取好的数据输入，并获得最终的一个结果1234567let output = array.reduce(function(accumulator, currentValue, currentIndex, array)&#123; //accumulator为输出结果 //currentValue为遍历数组目前的值 //currentIndex为遍历数组目前的索引 //array为被访问数组 return ;//返回希望累加的操作&#125;,0);//0为计算结果的初始值，默认为数组第一个元素 TODO在完成JS练习中，我时常会遇到以下问题待解决： 在Map操作中，经常会遇到需要根据已有的目标数组的情况做出相应的映射操作，但目前尚未发现怎样在Map循环中检查已映射的目标数组 为对象实现接口使对象也具有MapReduce操作的能力","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"blog.llsevenr.cn/tags/JavaScript/"},{"name":"collection","slug":"collection","permalink":"blog.llsevenr.cn/tags/collection/"},{"name":"集合","slug":"集合","permalink":"blog.llsevenr.cn/tags/集合/"},{"name":"遍历","slug":"遍历","permalink":"blog.llsevenr.cn/tags/遍历/"}]}]